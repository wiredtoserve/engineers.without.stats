{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import random\n",
    "import networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "with open(\"./train.txt\", 'r') as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    \n",
    "    for line in reader:\n",
    "        entry = list(map(int, line))\n",
    "        d[entry[0]] = entry[1:]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump dictionary (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./d.pickle\", \"wb\") as f:\n",
    "    pickle.dump(d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate 5k unconnected and 5k connected pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "random.seed(1)\n",
    "\n",
    "unconnected_pairs = []\n",
    "while len(unconnected_pairs) < 5000:\n",
    "    # generate random sample\n",
    "    x, y = random.sample(d.keys(), k=2)\n",
    "    \n",
    "    if x not in d[y] and y not in d[x] and (x,y) not in unconnected_pairs:\n",
    "        unconnected_pairs.append((x, y))\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "connected_pairs = []\n",
    "while len(connected_pairs) < 5000:\n",
    "    x = random.sample(d.keys(), k=1)[0]\n",
    "    try:\n",
    "        y = random.sample(d[x], k=1)[0]\n",
    "    \n",
    "        if (x,y) not in connected_pairs:\n",
    "            connected_pairs.append((x, y))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "print(\"done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(connected_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unconnected_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine lists and build graph from original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_pairs = connected_pairs + unconnected_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/26665799/networkx-adding-edges-to-a-graph-from-a-dictionary-with-lists-as-values\n",
    "G = networkx.Graph(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 4867136\n",
      "Number of edges: 23416061\n",
      "Average degree:   9.6221\n"
     ]
    }
   ],
   "source": [
    "print(networkx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = networkx.DiGraph(d)\n",
    "#J.add_edges_from(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_rank = nx.pagerank_scipy(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute graph metrics based on the 10k sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc = list(networkx.jaccard_coefficient(G, mixed_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1971490, 4521813),\n",
       " (2863976, 926731),\n",
       " (370525, 3608160),\n",
       " (3682375, 2984819),\n",
       " (4342778, 94321)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = list(networkx.resource_allocation_index(G, mixed_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = list(networkx.adamic_adar_index(G, mixed_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = list(networkx.preferential_attachment(G, mixed_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = [(e[0], e[1], len(list(networkx.common_neighbors(G,e[0], e[1])))) for e in mixed_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(G)):\n",
    "    G.nodes[i]['community'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_sh = list(networkx.cn_soundarajan_hopcroft(G, mixed_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_sh = list(networkx.ra_index_soundarajan_hopcroft(G, mixed_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wic = list(networkx.within_inter_cluster(G, mixed_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_rank_source = []\n",
    "page_rank_sink = []\n",
    "\n",
    " \n",
    "for (x,y) in string_pairs:\n",
    "    page_rank_source.append(page_rank[x])\n",
    "    page_rank_sink.append(page_rank[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_score, authority_score = nx.hits(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_source = []\n",
    "hub_sink = []\n",
    "authority_source = []\n",
    "authority_sink = []\n",
    "\n",
    "for (x,y) in string_pairs:\n",
    "    hub_source.append(hub_score[x])\n",
    "    hub_sink.append(hub_score[y])    \n",
    "    authority_source.append(authority_score[x])\n",
    "    authority_sink.append(authority_score[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_degree_centrality = nx.out_degree_centrality(J)\n",
    "in_degree_centrality = nx.in_degree_centrality(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_out_degree = []\n",
    "source_in_degree = []\n",
    "sink_out_degree = []\n",
    "sink_in_degree = []\n",
    "\n",
    "for (x,y) in string_pairs:\n",
    "    source_out_degree.append(out_degree_centrality[x])\n",
    "    sink_out_degree.append(out_degree_centrality[y])    \n",
    "    source_in_degree.append(in_degree_centrality[x])\n",
    "    sink_in_degree.append(in_degree_centrality[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = []\n",
    "for (x,y) in string_pairs:\n",
    "    try:\n",
    "        sp.append(nx.shortest_path_length(J, x, y))\n",
    "    except:\n",
    "        sp.append(0) # find the max and add one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pr = networkx.pagerank(G, alpha=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "ones = [1 for i in range(N)] + [0 for i in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data = [(\"Souce\", \"Sink\", \"Connected\", \"Jaccard\", \"Resource_alloc\", \"Adamic_adar\", \"Preferential_attachment\", \"Common Neighbours\", \"CN Sound-Hopcroft\", \"Resoruce Alloc Index\", \"Within Inner Cluster\")]\n",
    "for i,pair in enumerate(mixed_pairs):\n",
    "    entry = (pair[0], pair[1], ones[i], jc[i][2], ra[i][2], aa[i][2], pa[i][2], cn[i][2], cn_sh[i][2], ra_sh[i][2], wic[i][2])\n",
    "    write_data.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./trainData.csv\", 'w', newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(write_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create features for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "with open(\"./test-public.txt\", 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    \n",
    "#     for line in reader:\n",
    "#         entry = list(map(int, line))\n",
    "#         t[entry[0]] = entry[1:]\n",
    "    for line in reader:\n",
    "        test_list.append((line[1], line[2]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = test_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [(int(x), int(y)) for x,y in test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2184483, 1300190),\n",
       " (3151356, 1452193),\n",
       " (1579396, 193159),\n",
       " (1406432, 2481036),\n",
       " (2389638, 593017)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc_test = list(networkx.jaccard_coefficient(G, test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_test = list(networkx.resource_allocation_index(G, test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_test = list(networkx.adamic_adar_index(G, test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_test = list(networkx.preferential_attachment(G, test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_test = [(e[0], e[1], len(list(networkx.common_neighbors(G,e[0], e[1])))) for e in test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(G)):\n",
    "    G.nodes[i]['community'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_sh_test = list(networkx.cn_soundarajan_hopcroft(G, test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_sh_test = list(networkx.ra_index_soundarajan_hopcroft(G, test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wic_test = list(networkx.within_inter_cluster(G, test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data = [(\"Souce\", \"Sink\", \"Jaccard\", \"Resource_alloc\", \"Adamic_adar\", \"Preferential_attachment\", \"Common Neighbours\", \"CN Sound-Hopcroft\", \"Resoruce Alloc Index\", \"Within Inner Cluster\")]\n",
    "for i,pair in enumerate(test_list):\n",
    "    entry = (pair[0], pair[1], jc_test[i][2], ra_test[i][2], aa_test[i][2], pa_test[i][2], cn_test[i][2], cn_sh_test[i][2], ra_sh_test[i][2], wic_test[i][2])\n",
    "    write_data.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./testData.csv\", 'w', newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(write_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## node2vec implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = set()\n",
    "\n",
    "for i, j in test_list[1:]:\n",
    "    test_set.add(int(i))\n",
    "    test_set.add(int(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3948"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3523359, 4740709]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(d[1933312],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-1dc79ed41170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'z' is not defined"
     ]
    }
   ],
   "source": [
    "z[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink_generator = lambda x:random.sample(d[x],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_width = []\n",
    "for node in test_set:\n",
    "    \n",
    "    if node not in d.keys():\n",
    "        key = reverse_d[node]\n",
    "        my_width.append((key, node))\n",
    "                \n",
    "        #my_width.append((node,))\n",
    "        \n",
    "    elif len(d[node]) >= 2:\n",
    "        sinks = sink_generator(node)\n",
    "        my_width.append((node, sinks[0]))\n",
    "        my_width.append((node, sinks[1]))\n",
    "        \n",
    "    elif len(d[node]) == 1:\n",
    "        sink = d[node]\n",
    "        my_width.append((node, sink[0]))\n",
    "    \n",
    "    #else:\n",
    "    #    my_width.append((node,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6240"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6247"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1933312, 4568979),\n",
       " (1933312, 1470023),\n",
       " (3072002,),\n",
       " (2351112,),\n",
       " (2261005, 571350)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_width[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_depth = []\n",
    "\n",
    "for node_tup in my_width:\n",
    "    new_node = node_tup[-1]\n",
    "    if new_node in d.keys():\n",
    "        sink = d[new_node]\n",
    "        if sink:\n",
    "            my_depth.append((new_node, sink[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1326"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = my_width + my_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7566"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./node2vec/node2v.txt', 'w') as f:\n",
    "    for x,y in final_list:\n",
    "        f.writelines(f'{x} {y}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('train.txt') as test:                                                                                          \n",
    "    testz = csv.reader(test, delimiter='\\t')\n",
    "    data = list(testz)\n",
    "    \n",
    "with open('test-public.txt') as test2:                                                                                          \n",
    "    test2z = csv.reader(test2, delimiter='\\t')\n",
    "    test_data = list(test2z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "#turn training data into a list of tuples; where each one represents a relationship\n",
    "a = []\n",
    "b = []\n",
    "for i in range(len(data)):\n",
    "    a.append(data[i][0])\n",
    "#print(a[:2])\n",
    "\n",
    "for i in range(2):\n",
    "    print(len(data[i][1:]))\n",
    "y = []\n",
    "z = []\n",
    "for i in range(len(data)):\n",
    "    y = [a[i]]*len(data[i][1:])\n",
    "    z.extend(list(zip(y,data[i][1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_d = {}\n",
    "\n",
    "for x,y in z:\n",
    "    reverse_d[int(y)] = int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4867136"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reverse_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
